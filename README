General Information
===================
This is a prototype of deduplication system, named destor.
Destor is an experimental tool that may help implementing great ideas.

Features
========
1. Context-based chunking by rabin hash.
2. Chunk-level pipeline;
3. Container-based storage;
4. in-memory index and DDFS index;
5. LRU cache and Nearly-Optimal cache;
6. CFL monitor and selective deduplication;
7. Context-based rewriting algorithm (CBR).
8. Extreme Binning index without file-level dedup;
9. SiLo index;
10. History-based rewriting algorithm (HBR), and CBR-assisted HBR.
11. Capping rewriting algorithm, rolling forward assembly area algorithm, and capping-assisted HBR.

Related papers
==============
1. Avoiding the Disk Bottleneck in the Data Domain Deduplication File System, in FAST'08.
2. Extreme Binning: Scalable, Parallel Deduplication for Chunk-based File Backup, in MASCOTS'09.
3. SiLo: A Similarity-Locality based Near-Exact Deduplicatin Scheme with Low RAM Overhead and High Throughput, in USENIX'11.
4. Chunk Fragmentation Level: An Effective Indicator for Read Performance Degradation in Deduplication Storage, in HPCC'11.
5. Assuring Demanded Read Performance of Data Deduplication Storage with Backup Datasets, in MASCOTS'12. 
6. Reducing impact of data fragmentation caused by in-line deduplication, in SYSTOR'12.
7. Improving Restore Speed for Backup Systems that Use Inline Chunk-Based Deduplication, in FAST'13.

Environment
===========
Linux 64bit.

Dependencies
============
1. libssl-dev is required to calculate sha-1 digest;
2. GLib 2.32 or later version; 
3. libmysqlclient-dev is required;
4. Makefile is automatically generated by GNU autoconf and automake.

INSTALL
=======
If all dependencies are installed,
compiling destor is straightforward:

./configure
make
make install

To uninstall destor, run
make uninstall


Running
=======
If compile and install are successful, executable files, named destor, should be moved to /usr/local/bin by default.
You can create a config file, destor.config, in where you run destor.
A sample destor.config is in scripts directory,
and many scripts for experiment are also there.
Run rebuild script to clean data.

destor has provided four types of services:
1. start a backup job,
    destor <directory or file>
2. start a recovery job,
    destor -r<jobid> <dest directory>
3. lookup statistics of system,
    destor -s
4. help
    destor -h

Configure
=========
The configure file of destor, named destor.config, is a little complicated.
Actually it offers several parameters of deduplication system, such as index type(ram, ddfs etc.), cache type(LRU or Nearly-Optimal), rewriting algorithms(NO, CFL or CBR) etc.
1.INDEX_TYPE : indicates the fingerprint index. Destor support RAM, DDFS, EXBIN, SILO currently;
2.READ_CACHE_TYPE : the cache for read, destor now support LRU and OPT;
3.REWRITE : indicates whether using rewriting algorithm, destor support NO, CFL and CBR.
4.There are other parameters, be careful.

Bugs
====
1. Don't backup directories with extreme long path. If the dir tree of your dataset is complicated, you can use concat.py to concatenate all files into a single file. 
2. If the running destor is crashed artificially or unexpectedly, data consistency is not guaranted and you'd better run rebuild script.
3. Do NOT backup extreme large dataset with a huger number of chunk than 2^31.
4. Do NOT support concurrent backup/restore.
5. If working path in destor.config is modified, the rebuild script in scripts folder must be modified too.

Author
======
Min Fu,
Email : fumin@hust.edu.cn
blog : fomy.sinaapp.com
